{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90da2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import smtplib\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f569fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempe! SOYBEAN CHIPS by TCD\n",
      "RM15.00\n",
      "9 reviews\n"
     ]
    }
   ],
   "source": [
    "# Connect to website\n",
    "\n",
    "URL = 'https://www.tcdsnacks.com/products/tempe-soybean-chips-by-tcd'\n",
    "page = requests.get(URL, \"lxml\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#https://httpbin.org/get\n",
    "\n",
    "# Fetching the title\n",
    "\n",
    "product_name = soup.find(\"h1\").get_text()\n",
    "\n",
    "# Fetching the price\n",
    "\n",
    "price = soup.find(\"span\", {\"class\": \"price-item price-item--regular\"}).get_text()\n",
    "\n",
    "# Fetching number of reviews\n",
    "\n",
    "num_reviews = soup.find(\"span\", {\"class\": \"jdgm-prev-badge__text\"}).get_text()\n",
    "\n",
    "\n",
    "# Cleaning title, price, num_reviews\n",
    "\n",
    "product_name = product_name.strip()\n",
    "price = price.strip()\n",
    "num_reviews = num_reviews.strip()\n",
    "\n",
    "# Print title, price, num_reviews\n",
    "\n",
    "print(product_name)\n",
    "print(price)\n",
    "print(num_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffc56bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-18\n"
     ]
    }
   ],
   "source": [
    "today = datetime.date.today()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8515087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "header = ['Date', 'Product Name', 'Price', 'No. of Reviews']\n",
    "data = [today, product_name, price, num_reviews]\n",
    "\n",
    "# Commenting out so I do not accidentally overwrite my data\n",
    "# with open('/Users/aliaabdulaziz/Desktop/projects/web scraping/TCDWebScraperDataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(header)\n",
    "#     writer.writerow(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'/Users/aliaabdulaziz/Desktop/projects/web scraping/TCDWebScraperDataset.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b053e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appending data to the csv\n",
    "\n",
    "with open('/Users/aliaabdulaziz/Desktop/projects/web scraping/TCDWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "934aedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to get the data\n",
    "\n",
    "def updates():\n",
    "    URL = 'https://www.tcdsnacks.com/products/tempe-soybean-chips-by-tcd'\n",
    "    page = requests.get(URL, \"lxml\")\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    product_name = soup.find(\"h1\").get_text()\n",
    "    price = soup.find(\"span\", {\"class\": \"price-item price-item--regular\"}).get_text()\n",
    "    num_reviews = soup.find(\"span\", {\"class\": \"jdgm-prev-badge__text\"}).get_text()\n",
    "    product_name = product_name.strip()\n",
    "    price = price.strip()\n",
    "    num_reviews = num_reviews.strip()\n",
    "    \n",
    "    import datetime\n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    import csv\n",
    "    header = ['Date', 'Product Name', 'Price', 'No. of Reviews']\n",
    "    data = [today, product_name, price, num_reviews]\n",
    "    \n",
    "    with open('/Users/aliaabdulaziz/Desktop/projects/web scraping/TCDWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1f4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function updates() every 24 hours\n",
    "\n",
    "while(True):\n",
    "    updates()\n",
    "    time.sleep(86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e4fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'/Users/aliaabdulaziz/Desktop/projects/web scraping/TCDWebScraperDataset.csv')\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
